{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "pathawayer_dnn_colearn_01.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOKqHHZtyAzrqjiimWsuL8s",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/turguthaspolat/pathawayer/blob/main/pathawayer_dnn_colearn_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wTQ5_mbOPiI"
      },
      "source": [
        "\n",
        "<center>\n",
        "<h1><b>Predicting Land Cover Change</b></h1>\n",
        "<h2>By using remote sensing data - within the act of compromising AI & Blockchain.</h2>\n",
        "<h5>Project code name: <b>PathAwayer</b></h5>\n",
        "\n",
        "</center>\n",
        "<p><font face=\"cambria\" color=\"gray\"><i>** This project is carried out within my doctoral studies, which is researching artificial intelligence blockchain interoperability.</i></font></p>\n",
        "\n",
        "<font face=\"cambria\" color=\"gray\"><i>** This notebook has been inspired by the [Chris Brown & Nick Clinton EarthEngine + Tensorflow presentation](https://www.youtube.com/watch?v=w-1xfF0IaeU). It shows the step by step how to integrate Google Earth Engine and TensorFlow 2.0 in the same pipeline (EE->Tensorflow->EE).\n",
        "\n",
        "The codes used are inspired by the works of [Cesar Aybar](https://csaybar.github.io/).</i></font>\n",
        "\n",
        "---\n",
        "<h2>Problem Area</h2>\n",
        "<p>The natural land cover of the earth has been subjected to great changes over many years depending on human activities and different usage methods.\n",
        "\n",
        "Large cities in developing countries are subject to a dynamic urbanization process because of population growth and migration. Since the acceleration of the urbanization process, settlement components that are built continuously cause significant changes in land cover and use.\n",
        "\n",
        "These changes have a negative effect on the natural cover and **ecosystem**. Therefore, regular follow-up of changes due to urbanization and detecting the current situation is important.\n",
        "\n",
        "One of the most important image processing techniques in **remote sensing** science is *classification*. Utilizing the **Deep Neural Network** (DNN) binary-classification in prediction with remote sensing images, many use cases can be applied, such as land cover and usage purpose, water resources management, and change analysis.\n",
        "\n",
        "In this project, by using remote sensing satellite images, it's tried to estimate the vegetation cover and residential areas at a simple level with DNN binary classification for the Marmaris region in 2019.\n",
        "</p>\n",
        "<h2>Using Platforms</h2>\n",
        "<p>As a senior solutions architect who always tries to find the most optimized way, I guess the below architecture would be more sensible for this research project.</p>\n",
        "\n",
        "*   [Earth Engine](https://earthengine.google.com/) — geospatial analysis platform\n",
        "*   [Earth Engine Data Catalog](https://developers.google.com/earth-engine/datasets/) — comprehensive archive of geospatial data (including NLCD)\n",
        "*   [TensorFlow](https://www.tensorflow.org/) — machine learning platform with FCNN capabilities\n",
        "*   [AI Platform](https://cloud.google.com/ai-platform/) — TensorFlow model training\n",
        "*   [Colab](http://colab.research.google.com/) — Jupyter notebook server for workflow development\n",
        "<center>\n",
        "<img src=\"https://miro.medium.com/max/3200/0*xVXtPYUw8h2bvd7M\">\n",
        "</center> \n",
        "\n",
        "<h2>Data from Google Earth Engine</h2>\n",
        "\n",
        "Within the scope of the project, the [Landsat 8 Surface Reflectance Tier 1](https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LC08_C01_T1_SR) data set, *freely available to use* - by Google Earth Engine (GEE) was used.\n",
        "LANDSAT satellites, a joint program of USGS and NASA, provide images of the entire earth's surface at a resolution of 30 meters every two weeks, including multispectral and thermal data.\n",
        "\n",
        "This dataset is atmospheric corrected surface reflection from Landsat 8 OLI / TIRS sensors. These images contain 5 visible and near infrared (VNIR) bands and 2 short-wave infrared (SWIR) bands processed into orthorectified surface reflection and two thermal infrared (TIR) ​​bands processed to orthorectified luminance temperature.\n",
        "\n",
        "The data obtained are stored separately for each band detected by the sensor. In order to create a multicolored image, band merging of the downloaded image has been done. For the purpose of this study, a multicolored image was created by combining Red-Green-Blue and Near Infrared bands (Band 2-Band 3- Band 4-Band 5 for Landsat 8).\n",
        "\n",
        "<h3>Prediction Area</h3>\n",
        "\n",
        "In the project, an area of approximately 10 km2 (3.5km x 3km) that will cover the **Marmaris** / Akyaka - Turkey environment is determined as the predction area and the model is planned to estimate over this area.\n",
        "\n",
        "\n",
        "<center>\n",
        "<img src=\"https://media-exp1.licdn.com/dms/image/C4D22AQHEl6i4NLL-Ng/feedshare-shrink_800/0/1619435849862?e=1623283200&v=beta&t=30ypGSa85v0plKJ8Z94kD26ykIHqYUwSSGw9XBmpSPU\">\n",
        "</center> \n",
        "\n",
        "<h3>Labeling Test/Trainind Data</h3>\n",
        "\n",
        "Data sets consist of 2 classes via Google Earth Engine; [1] It is simply labeled into Vegetation (green dots) and [2] Settlement Area (red dots), with 800 (400: [1] - 400: [2]) training and 200 (100: [1]) - 100: [2]) tagged via GEE as the test data set. The mentioned labeling table has been saved as an asset in GEE.\n",
        "\n",
        "<h2>Methods</h2>\n",
        "\n",
        "In this project, **TensorFlow Keras Sequential model** is used as the DNN model.\n",
        "While the model is being trained, *Keras callback* editor calls have been added, which allow monitoring the training process in order to accelerate convergence, avoid overfitting and reach the most optimum model.\n",
        "\n",
        "**validation_loss** is set to halt the training process if it loses value at 10 epochs. Finally, in the model, the **ModelCheckpoint** function has been adjusted to get the value where the **validation_loss** value reaches the best value by saving it to the given variable.\n",
        "\n",
        "The model compilation is **Stochastic Gradient Descent (SGD)** and **binary_crossentropy** loss function is used for its optimization.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxnK07XXuQRo"
      },
      "source": [
        "### 1. **Authentication**\n",
        "Needs interaction with Google services as mentioned in the proposed architecture. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksV0TIlYNqbx"
      },
      "source": [
        "#### 1.1 Google Cloud\n",
        "\n",
        "Google Cloud Storage bucket will serve as a bridge between GEE and Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Uj_IwNUMmJG"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40Bb1yewNvfp"
      },
      "source": [
        "#### 1.2 Google Earth Engine\n",
        "it's possible to run the **Earth Engine Python API** in a cloud environment as free of use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdLd4VcANzBs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "422bb9d4-117f-4de6-9358-40dcb5d7600c"
      },
      "source": [
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "To authorize access needed by Earth Engine, open the following URL in a web browser and follow the instructions. If the web browser does not start automatically, please manually browse the URL below.\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=CN4BOj_R6JloqF7MzrC6xNNYVUutmCEi8R52RjlzgU4&code_challenge_method=S256\n",
            "\n",
            "The authorization workflow will generate a code, which you should paste in the box below. \n",
            "Enter verification code: 4/1AY0e-g4ovCHAGHe3U2rDrcyryT7m9rau-Ll2Lw09pQ9eU58_-BrBVLpjVGw\n",
            "\n",
            "Successfully saved authorization token.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0N7sdqmZN1yL"
      },
      "source": [
        "### **2. Initializing Frameworks and Libraries**\n",
        "**Tensorflow** is using via Google Colab (Jupyter notebook server) to train and test the model.\n",
        "\n",
        "Integration of Google Cloud with AI Platform will provide to connect Google Earth Engine data set data directly to TensorFlow models in real-time. Training and test data sets on the data sets are being recorded on **Google Cloud Storage**.\n",
        "\n",
        "**Folium** library, *which uses the JavaScript leaflet.js module in the background and provides interactive map display in Python*, will be used to visualize the data sets on the map."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk2AdjwMb5c-"
      },
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYxjWLC7QMCZ",
        "outputId": "932ecd13-0e19-4d84-c9b2-ae542119ba4d"
      },
      "source": [
        "import tensorflow as tf\n",
        "print('Tensorflow version: ' + tf.__version__)\n",
        "\n",
        "import folium\n",
        "print('Folium version: ' + folium.__version__)\n",
        "\n",
        "# Define the URL format used for Earth Engine generated map tiles.\n",
        "EE_TILES = 'https://earthengine.googleapis.com/map/{mapid}/{{z}}/{{x}}/{{y}}?token={token}'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version: 2.5.0\n",
            "Folium version: 0.8.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS8iU-MDRnFO"
      },
      "source": [
        "### **3. Display Map**\n",
        "Display google earth engine map feature collection; `ee.Features` and `ee.Images` on map using folium."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ7ya9DyR0th"
      },
      "source": [
        "def Mapdisplay(center, dicc, Tiles=\"OpensTreetMap\",zoom_start=10):\n",
        "    '''\n",
        "    :param center: Center of the map (Latitude and Longitude).\n",
        "    :param dicc: Earth Engine Geometries or Tiles dictionary\n",
        "    :param Tiles: Mapbox Bright,Mapbox Control Room,Stamen Terrain,Stamen Toner,stamenwatercolor,cartodbpositron.\n",
        "    :zoom_start: Initial zoom level for the map.\n",
        "    :return: A folium.Map object.\n",
        "    '''\n",
        "    mapViz = folium.Map(location=center,tiles=Tiles, zoom_start=zoom_start)\n",
        "    for k,v in dicc.items():\n",
        "      if ee.image.Image in [type(x) for x in v.values()]:\n",
        "        folium.TileLayer(\n",
        "            tiles = v[\"tile_fetcher\"].url_format,\n",
        "            attr  = 'Google Earth Engine',\n",
        "            overlay =True,\n",
        "            name  = k\n",
        "          ).add_to(mapViz)\n",
        "      else:\n",
        "        folium.GeoJson(\n",
        "        data = v,\n",
        "        name = k\n",
        "          ).add_to(mapViz)\n",
        "    mapViz.add_child(folium.LayerControl())\n",
        "    return mapViz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAwz4a7kSsXw"
      },
      "source": [
        "#### 3.1 Displaying Defined Prediction Area\n",
        "As defining our prediction area (Marmaris-Akyaka, Turkey), it will be passed the vector using `ee.Geometry.*` module supported by GEE, including `Point` (a list of coordinates in some projection), `LineString` (a list of points), `LinearRing` (a closed LineString), and `Polygon`. \n",
        "\n",
        "GEE also supports **MultiPoint**, **MultiLineString**, and **MultiPolygon**. The [GeoJSON](https://geojson.org/) GeometryCollection is also supported."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 968
        },
        "id": "6Dparl17SrlS",
        "outputId": "bfcddf04-543d-4091-bbde-95711de9e5d5"
      },
      "source": [
        "# Prediction Area - Marmaris-Akyaka, Turkey\n",
        "xmin,ymin,xmax,ymax = [28.3159, 37.0471, 28.3566, 37.0652]\n",
        "\n",
        "# Defining workspace coordinates for Google Earth Engine\n",
        "Marmaris = ee.Geometry.Rectangle([xmin,ymin,xmax,ymax])\n",
        "center = Marmaris.centroid().getInfo()['coordinates']\n",
        "center.reverse()\n",
        "Mapdisplay(center,{'Marmaris':Marmaris.getInfo()},zoom_start=12)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe src=\"about:blank\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" data-html=%3C%21DOCTYPE%20html%3E%0A%3Chead%3E%20%20%20%20%0A%20%20%20%20%3Cmeta%20http-equiv%3D%22content-type%22%20content%3D%22text/html%3B%20charset%3DUTF-8%22%20/%3E%0A%20%20%20%20%3Cscript%3EL_PREFER_CANVAS%3Dfalse%3B%20L_NO_TOUCH%3Dfalse%3B%20L_DISABLE_3D%3Dfalse%3B%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//cdn.jsdelivr.net/npm/leaflet%401.4.0/dist/leaflet.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//code.jquery.com/jquery-1.12.4.min.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js%22%3E%3C/script%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//cdn.jsdelivr.net/npm/leaflet%401.4.0/dist/leaflet.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap-theme.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//rawcdn.githack.com/python-visualization/folium/master/folium/templates/leaflet.awesome.rotate.css%22/%3E%0A%20%20%20%20%3Cstyle%3Ehtml%2C%20body%20%7Bwidth%3A%20100%25%3Bheight%3A%20100%25%3Bmargin%3A%200%3Bpadding%3A%200%3B%7D%3C/style%3E%0A%20%20%20%20%3Cstyle%3E%23map%20%7Bposition%3Aabsolute%3Btop%3A0%3Bbottom%3A0%3Bright%3A0%3Bleft%3A0%3B%7D%3C/style%3E%0A%20%20%20%20%0A%20%20%20%20%3Cmeta%20name%3D%22viewport%22%20content%3D%22width%3Ddevice-width%2C%0A%20%20%20%20%20%20%20%20initial-scale%3D1.0%2C%20maximum-scale%3D1.0%2C%20user-scalable%3Dno%22%20/%3E%0A%20%20%20%20%3Cstyle%3E%23map_a3a2fc08bc9447aa86f7bc78506bdcb3%20%7B%0A%20%20%20%20%20%20%20%20position%3A%20relative%3B%0A%20%20%20%20%20%20%20%20width%3A%20100.0%25%3B%0A%20%20%20%20%20%20%20%20height%3A%20100.0%25%3B%0A%20%20%20%20%20%20%20%20left%3A%200.0%25%3B%0A%20%20%20%20%20%20%20%20top%3A%200.0%25%3B%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%3C/style%3E%0A%3C/head%3E%0A%3Cbody%3E%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%3Cdiv%20class%3D%22folium-map%22%20id%3D%22map_a3a2fc08bc9447aa86f7bc78506bdcb3%22%20%3E%3C/div%3E%0A%3C/body%3E%0A%3Cscript%3E%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20var%20bounds%20%3D%20null%3B%0A%20%20%20%20%0A%0A%20%20%20%20var%20map_a3a2fc08bc9447aa86f7bc78506bdcb3%20%3D%20L.map%28%0A%20%20%20%20%20%20%20%20%27map_a3a2fc08bc9447aa86f7bc78506bdcb3%27%2C%20%7B%0A%20%20%20%20%20%20%20%20center%3A%20%5B37.05615137814542%2C%2028.33624999999642%5D%2C%0A%20%20%20%20%20%20%20%20zoom%3A%2012%2C%0A%20%20%20%20%20%20%20%20maxBounds%3A%20bounds%2C%0A%20%20%20%20%20%20%20%20layers%3A%20%5B%5D%2C%0A%20%20%20%20%20%20%20%20worldCopyJump%3A%20false%2C%0A%20%20%20%20%20%20%20%20crs%3A%20L.CRS.EPSG3857%2C%0A%20%20%20%20%20%20%20%20zoomControl%3A%20true%2C%0A%20%20%20%20%20%20%20%20%7D%29%3B%0A%0A%0A%20%20%20%20%0A%20%20%20%20var%20tile_layer_3df0b58e6b5c4294a8dbcd69d0294192%20%3D%20L.tileLayer%28%0A%20%20%20%20%20%20%20%20%27https%3A//%7Bs%7D.tile.openstreetmap.org/%7Bz%7D/%7Bx%7D/%7By%7D.png%27%2C%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%22attribution%22%3A%20null%2C%0A%20%20%20%20%20%20%20%20%22detectRetina%22%3A%20false%2C%0A%20%20%20%20%20%20%20%20%22maxNativeZoom%22%3A%2018%2C%0A%20%20%20%20%20%20%20%20%22maxZoom%22%3A%2018%2C%0A%20%20%20%20%20%20%20%20%22minZoom%22%3A%200%2C%0A%20%20%20%20%20%20%20%20%22noWrap%22%3A%20false%2C%0A%20%20%20%20%20%20%20%20%22opacity%22%3A%201%2C%0A%20%20%20%20%20%20%20%20%22subdomains%22%3A%20%22abc%22%2C%0A%20%20%20%20%20%20%20%20%22tms%22%3A%20false%0A%7D%29.addTo%28map_a3a2fc08bc9447aa86f7bc78506bdcb3%29%3B%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20var%20geo_json_39e555e9ea6f4afc99176b9f150d736f%20%3D%20L.geoJson%28%0A%20%20%20%20%20%20%20%20%20%20%20%20%7B%22features%22%3A%20%5B%7B%22geometry%22%3A%20%7B%22coordinates%22%3A%20%5B%5B%5B28.3159%2C%2037.0471%5D%2C%20%5B28.3566%2C%2037.0471%5D%2C%20%5B28.3566%2C%2037.0652%5D%2C%20%5B28.3159%2C%2037.0652%5D%2C%20%5B28.3159%2C%2037.0471%5D%5D%5D%2C%20%22type%22%3A%20%22Polygon%22%7D%2C%20%22properties%22%3A%20%7B%22highlight%22%3A%20%7B%7D%2C%20%22style%22%3A%20%7B%7D%7D%2C%20%22type%22%3A%20%22Feature%22%7D%5D%2C%20%22type%22%3A%20%22FeatureCollection%22%7D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%29.addTo%28map_a3a2fc08bc9447aa86f7bc78506bdcb3%20%29%3B%0A%20%20%20%20%20%20%20%20geo_json_39e555e9ea6f4afc99176b9f150d736f.setStyle%28function%28feature%29%20%7Breturn%20feature.properties.style%3B%7D%29%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20var%20layer_control_6c57db9349e84e23af31faeb257cd467%20%3D%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20base_layers%20%3A%20%7B%20%22openstreetmap%22%20%3A%20tile_layer_3df0b58e6b5c4294a8dbcd69d0294192%2C%20%7D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20overlays%20%3A%20%7B%20%22Marmaris%22%20%3A%20geo_json_39e555e9ea6f4afc99176b9f150d736f%2C%20%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20L.control.layers%28%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20layer_control_6c57db9349e84e23af31faeb257cd467.base_layers%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20layer_control_6c57db9349e84e23af31faeb257cd467.overlays%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7Bposition%3A%20%27topright%27%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20collapsed%3A%20true%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20autoZIndex%3A%20true%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%29.addTo%28map_a3a2fc08bc9447aa86f7bc78506bdcb3%29%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%0A%3C/script%3E onload=\"this.contentDocument.open();this.contentDocument.write(    decodeURIComponent(this.getAttribute('data-html')));this.contentDocument.close();\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ],
            "text/plain": [
              "<folium.folium.Map at 0x7f2a4c1fbf10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tBzV-9VYRmw"
      },
      "source": [
        "#### 3.2 Displaying Labeled Test/Training Dataset\n",
        "It's been already generated points labeled as (green) agriculture and (red) non-agirculture.\n",
        "\n",
        "- Train dataset (800 points):\n",
        "  - 400 labeled as \"agriculture\"\n",
        "  - 400 labeled as \"non agriculture\" \n",
        "  \n",
        "- Test dataset (200 points):\n",
        "  - 100  labeled as \"agriculture\"\n",
        "  - 100  labeled as \"non agriculture\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 968
        },
        "id": "jjMl2cuPZ_yq",
        "outputId": "a591e7c0-a115-442d-bc76-2b5dcba4f252"
      },
      "source": [
        "# Importing the train/test dataset from GEE\n",
        "train_agriculture = ee.FeatureCollection('users/patikan/marmaris_agronomy_train_set') \n",
        "test_agriculture = ee.FeatureCollection('users/patikan/marmaris_agronomy_test_set')\n",
        "\n",
        "# Display the train/test dataset\n",
        "db_crop = train_agriculture.merge(test_agriculture)\n",
        "center = db_crop.geometry().centroid().getInfo()['coordinates']\n",
        "center.reverse()\n",
        "\n",
        "dicc = {'train': train_agriculture.draw(**{'color': '3b8b00', 'strokeWidth': 5}).getMapId(),\n",
        "        'test' : test_agriculture.draw(**{'color': 'fcb103', 'strokeWidth': 5}).getMapId(),\n",
        "        'Marmaris':Marmaris.getInfo()\n",
        "       }\n",
        "\n",
        "Mapdisplay(center,dicc,zoom_start=12)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe src=\"about:blank\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" data-html=%3C%21DOCTYPE%20html%3E%0A%3Chead%3E%20%20%20%20%0A%20%20%20%20%3Cmeta%20http-equiv%3D%22content-type%22%20content%3D%22text/html%3B%20charset%3DUTF-8%22%20/%3E%0A%20%20%20%20%3Cscript%3EL_PREFER_CANVAS%3Dfalse%3B%20L_NO_TOUCH%3Dfalse%3B%20L_DISABLE_3D%3Dfalse%3B%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//cdn.jsdelivr.net/npm/leaflet%401.4.0/dist/leaflet.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//code.jquery.com/jquery-1.12.4.min.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js%22%3E%3C/script%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//cdn.jsdelivr.net/npm/leaflet%401.4.0/dist/leaflet.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap-theme.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//rawcdn.githack.com/python-visualization/folium/master/folium/templates/leaflet.awesome.rotate.css%22/%3E%0A%20%20%20%20%3Cstyle%3Ehtml%2C%20body%20%7Bwidth%3A%20100%25%3Bheight%3A%20100%25%3Bmargin%3A%200%3Bpadding%3A%200%3B%7D%3C/style%3E%0A%20%20%20%20%3Cstyle%3E%23map%20%7Bposition%3Aabsolute%3Btop%3A0%3Bbottom%3A0%3Bright%3A0%3Bleft%3A0%3B%7D%3C/style%3E%0A%20%20%20%20%0A%20%20%20%20%3Cmeta%20name%3D%22viewport%22%20content%3D%22width%3Ddevice-width%2C%0A%20%20%20%20%20%20%20%20initial-scale%3D1.0%2C%20maximum-scale%3D1.0%2C%20user-scalable%3Dno%22%20/%3E%0A%20%20%20%20%3Cstyle%3E%23map_85d201fdc86a409fb7d2c4a0d0d5c70c%20%7B%0A%20%20%20%20%20%20%20%20position%3A%20relative%3B%0A%20%20%20%20%20%20%20%20width%3A%20100.0%25%3B%0A%20%20%20%20%20%20%20%20height%3A%20100.0%25%3B%0A%20%20%20%20%20%20%20%20left%3A%200.0%25%3B%0A%20%20%20%20%20%20%20%20top%3A%200.0%25%3B%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%3C/style%3E%0A%3C/head%3E%0A%3Cbody%3E%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%3Cdiv%20class%3D%22folium-map%22%20id%3D%22map_85d201fdc86a409fb7d2c4a0d0d5c70c%22%20%3E%3C/div%3E%0A%3C/body%3E%0A%3Cscript%3E%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20var%20bounds%20%3D%20null%3B%0A%20%20%20%20%0A%0A%20%20%20%20var%20map_85d201fdc86a409fb7d2c4a0d0d5c70c%20%3D%20L.map%28%0A%20%20%20%20%20%20%20%20%27map_85d201fdc86a409fb7d2c4a0d0d5c70c%27%2C%20%7B%0A%20%20%20%20%20%20%20%20center%3A%20%5B36.85529666496596%2C%2028.228219974785265%5D%2C%0A%20%20%20%20%20%20%20%20zoom%3A%2012%2C%0A%20%20%20%20%20%20%20%20maxBounds%3A%20bounds%2C%0A%20%20%20%20%20%20%20%20layers%3A%20%5B%5D%2C%0A%20%20%20%20%20%20%20%20worldCopyJump%3A%20false%2C%0A%20%20%20%20%20%20%20%20crs%3A%20L.CRS.EPSG3857%2C%0A%20%20%20%20%20%20%20%20zoomControl%3A%20true%2C%0A%20%20%20%20%20%20%20%20%7D%29%3B%0A%0A%0A%20%20%20%20%0A%20%20%20%20var%20tile_layer_390a2a83b0cc4dc59dc65fe5ffd9d706%20%3D%20L.tileLayer%28%0A%20%20%20%20%20%20%20%20%27https%3A//%7Bs%7D.tile.openstreetmap.org/%7Bz%7D/%7Bx%7D/%7By%7D.png%27%2C%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%22attribution%22%3A%20null%2C%0A%20%20%20%20%20%20%20%20%22detectRetina%22%3A%20false%2C%0A%20%20%20%20%20%20%20%20%22maxNativeZoom%22%3A%2018%2C%0A%20%20%20%20%20%20%20%20%22maxZoom%22%3A%2018%2C%0A%20%20%20%20%20%20%20%20%22minZoom%22%3A%200%2C%0A%20%20%20%20%20%20%20%20%22noWrap%22%3A%20false%2C%0A%20%20%20%20%20%20%20%20%22opacity%22%3A%201%2C%0A%20%20%20%20%20%20%20%20%22subdomains%22%3A%20%22abc%22%2C%0A%20%20%20%20%20%20%20%20%22tms%22%3A%20false%0A%7D%29.addTo%28map_85d201fdc86a409fb7d2c4a0d0d5c70c%29%3B%0A%20%20%20%20var%20tile_layer_fa1aa5afc979413294a89ef1e58c2ddd%20%3D%20L.tileLayer%28%0A%20%20%20%20%20%20%20%20%27https%3A//earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/bdf575eff9be08718c6c87c7f5094188-bc2a514d95509f138fc4192348471647/tiles/%7Bz%7D/%7Bx%7D/%7By%7D%27%2C%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%22attribution%22%3A%20%22Google%20Earth%20Engine%22%2C%0A%20%20%20%20%20%20%20%20%22detectRetina%22%3A%20false%2C%0A%20%20%20%20%20%20%20%20%22maxNativeZoom%22%3A%2018%2C%0A%20%20%20%20%20%20%20%20%22maxZoom%22%3A%2018%2C%0A%20%20%20%20%20%20%20%20%22minZoom%22%3A%200%2C%0A%20%20%20%20%20%20%20%20%22noWrap%22%3A%20false%2C%0A%20%20%20%20%20%20%20%20%22opacity%22%3A%201%2C%0A%20%20%20%20%20%20%20%20%22subdomains%22%3A%20%22abc%22%2C%0A%20%20%20%20%20%20%20%20%22tms%22%3A%20false%0A%7D%29.addTo%28map_85d201fdc86a409fb7d2c4a0d0d5c70c%29%3B%0A%20%20%20%20var%20tile_layer_8a3b5021db004c31a0fc52404b0d7c82%20%3D%20L.tileLayer%28%0A%20%20%20%20%20%20%20%20%27https%3A//earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/72089158f7d9340f815eadf450ae5b22-83d545ff831de5de36ffe2a6f9e324b0/tiles/%7Bz%7D/%7Bx%7D/%7By%7D%27%2C%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%22attribution%22%3A%20%22Google%20Earth%20Engine%22%2C%0A%20%20%20%20%20%20%20%20%22detectRetina%22%3A%20false%2C%0A%20%20%20%20%20%20%20%20%22maxNativeZoom%22%3A%2018%2C%0A%20%20%20%20%20%20%20%20%22maxZoom%22%3A%2018%2C%0A%20%20%20%20%20%20%20%20%22minZoom%22%3A%200%2C%0A%20%20%20%20%20%20%20%20%22noWrap%22%3A%20false%2C%0A%20%20%20%20%20%20%20%20%22opacity%22%3A%201%2C%0A%20%20%20%20%20%20%20%20%22subdomains%22%3A%20%22abc%22%2C%0A%20%20%20%20%20%20%20%20%22tms%22%3A%20false%0A%7D%29.addTo%28map_85d201fdc86a409fb7d2c4a0d0d5c70c%29%3B%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20var%20geo_json_d2e115fb3f4d44c7835cf4c996443699%20%3D%20L.geoJson%28%0A%20%20%20%20%20%20%20%20%20%20%20%20%7B%22features%22%3A%20%5B%7B%22geometry%22%3A%20%7B%22coordinates%22%3A%20%5B%5B%5B28.3159%2C%2037.0471%5D%2C%20%5B28.3566%2C%2037.0471%5D%2C%20%5B28.3566%2C%2037.0652%5D%2C%20%5B28.3159%2C%2037.0652%5D%2C%20%5B28.3159%2C%2037.0471%5D%5D%5D%2C%20%22type%22%3A%20%22Polygon%22%7D%2C%20%22properties%22%3A%20%7B%22highlight%22%3A%20%7B%7D%2C%20%22style%22%3A%20%7B%7D%7D%2C%20%22type%22%3A%20%22Feature%22%7D%5D%2C%20%22type%22%3A%20%22FeatureCollection%22%7D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%29.addTo%28map_85d201fdc86a409fb7d2c4a0d0d5c70c%20%29%3B%0A%20%20%20%20%20%20%20%20geo_json_d2e115fb3f4d44c7835cf4c996443699.setStyle%28function%28feature%29%20%7Breturn%20feature.properties.style%3B%7D%29%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20var%20layer_control_e9eb98eaf44944c59017e3a30d022656%20%3D%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20base_layers%20%3A%20%7B%20%22openstreetmap%22%20%3A%20tile_layer_390a2a83b0cc4dc59dc65fe5ffd9d706%2C%20%7D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20overlays%20%3A%20%7B%20%22train%22%20%3A%20tile_layer_fa1aa5afc979413294a89ef1e58c2ddd%2C%22test%22%20%3A%20tile_layer_8a3b5021db004c31a0fc52404b0d7c82%2C%22Marmaris%22%20%3A%20geo_json_d2e115fb3f4d44c7835cf4c996443699%2C%20%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20L.control.layers%28%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20layer_control_e9eb98eaf44944c59017e3a30d022656.base_layers%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20layer_control_e9eb98eaf44944c59017e3a30d022656.overlays%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7Bposition%3A%20%27topright%27%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20collapsed%3A%20true%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20autoZIndex%3A%20true%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%29.addTo%28map_85d201fdc86a409fb7d2c4a0d0d5c70c%29%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%0A%3C/script%3E onload=\"this.contentDocument.open();this.contentDocument.write(    decodeURIComponent(this.getAttribute('data-html')));this.contentDocument.close();\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ],
            "text/plain": [
              "<folium.folium.Map at 0x7f2a0953c750>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TwdYzUwcBAs"
      },
      "source": [
        "#### 3.3 Applying Cloud Mask Filter\n",
        "**Cloud masking** is a very important application in remote sensing and an essential pre-processing step for any information derivation applications. \n",
        "\n",
        "The basic idea of this approach is to detect cloud and cloud shadow by using the difference reflectance values between clear pixels and cloud and cloud shadow contaminated pixels.\n",
        "\n",
        "GEE provides [Landsat 8 OLI/TIRS (L8)](https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LC08_C01_T1_SR) images with radiometric and geometry correction. **Cloud mask** is provided by means of the bit image `pixel_qa`. \n",
        "\n",
        "The following function allows obtaining the input data for mapping the **Marmaris** are using **Landsat 8 OLI/TIRS (L8)**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRQx1YN7eAFl"
      },
      "source": [
        "def maskS2clouds(img):\n",
        "  '''  \n",
        "  Function to mask clouds based on the pixel_qa band of Landsat 8 SR data. See:\n",
        "  https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LC08_C01_T1_SR\n",
        "  \n",
        "  Params:\n",
        "  -------\n",
        "  - img: image input Landsat 8 SR image\n",
        "  \n",
        "  Return:\n",
        "  -------\n",
        "  cloudmasked Landsat 8 image\n",
        "  '''\n",
        "  cloudShadowBitMask = (1 << 3)\n",
        "  cloudsBitMask = (1 << 5)\n",
        "  # Get the pixel QA band.\n",
        "  qa = img.select('pixel_qa')\n",
        "  # Both flags should be set to zero, indicating clear conditions.\n",
        "  mask = qa.bitwiseAnd(cloudShadowBitMask).eq(0)\\\n",
        "           .And(qa.bitwiseAnd(cloudsBitMask).eq(0))\n",
        "  return img.updateMask(mask)     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZLnhmfzeJyU"
      },
      "source": [
        "#### 3.4 Displaying the Filtered L8 Dataset\n",
        "Applying the following filtering and reducing operations to the Landsat 8 dataset;\n",
        "\n",
        "1. Select specific bands **[R, G, B, NIR]**.\n",
        "\n",
        "2. Filter considering the cloud pixel percentage by scene (< 20%).\n",
        "\n",
        "3. Filter considering a date (selected 2019)\n",
        "\n",
        "4. Apply **mask2cloud** to each image.\n",
        "\n",
        "5. Get the median of the ImageCollection.\n",
        "\n",
        "6. Clip the image considering study area."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 968
        },
        "id": "J611LQGff44o",
        "outputId": "289cfc5e-0246-447d-da6d-c3e7534d99ef"
      },
      "source": [
        "# Prepare the satellite image (Landsat-8)\n",
        "RGB_bands = ['B4','B3','B2'] #RGB\n",
        "NDVI_bands = ['B5','B4'] #NIR\n",
        "\n",
        "l8 = ee.ImageCollection(\"LANDSAT/LC08/C01/T1_SR\")\\\n",
        "               .filterBounds(db_crop)\\\n",
        "               .filterDate('2019-01-01', '2019-12-31')\\\n",
        "               .filter(ee.Filter.lt('CLOUD_COVER', 20))\\\n",
        "               .map(maskS2clouds)\\\n",
        "               .median()\\\n",
        "               .multiply(0.0001)\n",
        "\n",
        "l8_ndvi = l8.normalizedDifference(NDVI_bands).rename(['NDVI'])\n",
        "l8_rgb = l8.select(RGB_bands).rename(['R','G','B']) \n",
        "l8 = l8_rgb.addBands(l8_ndvi)\n",
        "\n",
        "from collections import OrderedDict\n",
        "# Create a visualization with folium\n",
        "visParams_l8 = {    \n",
        "  'bands': ['R', 'G', 'B'],\n",
        "  'min': 0,\n",
        "  'max': 0.5,\n",
        "  'gamma': 1.4,\n",
        "}\n",
        "\n",
        "l8Mapid = l8.getMapId(visParams_l8)\n",
        "dicc['Landsat8'] = l8Mapid\n",
        "\n",
        "# Changing the order of the dictionary\n",
        "key_order = ['Landsat8','Marmaris','train','test']\n",
        "dicc = OrderedDict((k, dicc[k]) for k in key_order)\n",
        "\n",
        "Mapdisplay(center,dicc,zoom_start=12)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe src=\"about:blank\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" data-html=%3C%21DOCTYPE%20html%3E%0A%3Chead%3E%20%20%20%20%0A%20%20%20%20%3Cmeta%20http-equiv%3D%22content-type%22%20content%3D%22text/html%3B%20charset%3DUTF-8%22%20/%3E%0A%20%20%20%20%3Cscript%3EL_PREFER_CANVAS%3Dfalse%3B%20L_NO_TOUCH%3Dfalse%3B%20L_DISABLE_3D%3Dfalse%3B%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//cdn.jsdelivr.net/npm/leaflet%401.4.0/dist/leaflet.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//code.jquery.com/jquery-1.12.4.min.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js%22%3E%3C/script%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//cdn.jsdelivr.net/npm/leaflet%401.4.0/dist/leaflet.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap-theme.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//rawcdn.githack.com/python-visualization/folium/master/folium/templates/leaflet.awesome.rotate.css%22/%3E%0A%20%20%20%20%3Cstyle%3Ehtml%2C%20body%20%7Bwidth%3A%20100%25%3Bheight%3A%20100%25%3Bmargin%3A%200%3Bpadding%3A%200%3B%7D%3C/style%3E%0A%20%20%20%20%3Cstyle%3E%23map%20%7Bposition%3Aabsolute%3Btop%3A0%3Bbottom%3A0%3Bright%3A0%3Bleft%3A0%3B%7D%3C/style%3E%0A%20%20%20%20%0A%20%20%20%20%3Cmeta%20name%3D%22viewport%22%20content%3D%22width%3Ddevice-width%2C%0A%20%20%20%20%20%20%20%20initial-scale%3D1.0%2C%20maximum-scale%3D1.0%2C%20user-scalable%3Dno%22%20/%3E%0A%20%20%20%20%3Cstyle%3E%23map_e02ab327738e4179821f653b49a66421%20%7B%0A%20%20%20%20%20%20%20%20position%3A%20relative%3B%0A%20%20%20%20%20%20%20%20width%3A%20100.0%25%3B%0A%20%20%20%20%20%20%20%20height%3A%20100.0%25%3B%0A%20%20%20%20%20%20%20%20left%3A%200.0%25%3B%0A%20%20%20%20%20%20%20%20top%3A%200.0%25%3B%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%3C/style%3E%0A%3C/head%3E%0A%3Cbody%3E%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%3Cdiv%20class%3D%22folium-map%22%20id%3D%22map_e02ab327738e4179821f653b49a66421%22%20%3E%3C/div%3E%0A%3C/body%3E%0A%3Cscript%3E%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20var%20bounds%20%3D%20null%3B%0A%20%20%20%20%0A%0A%20%20%20%20var%20map_e02ab327738e4179821f653b49a66421%20%3D%20L.map%28%0A%20%20%20%20%20%20%20%20%27map_e02ab327738e4179821f653b49a66421%27%2C%20%7B%0A%20%20%20%20%20%20%20%20center%3A%20%5B36.85529666496596%2C%2028.228219974785265%5D%2C%0A%20%20%20%20%20%20%20%20zoom%3A%2012%2C%0A%20%20%20%20%20%20%20%20maxBounds%3A%20bounds%2C%0A%20%20%20%20%20%20%20%20layers%3A%20%5B%5D%2C%0A%20%20%20%20%20%20%20%20worldCopyJump%3A%20false%2C%0A%20%20%20%20%20%20%20%20crs%3A%20L.CRS.EPSG3857%2C%0A%20%20%20%20%20%20%20%20zoomControl%3A%20true%2C%0A%20%20%20%20%20%20%20%20%7D%29%3B%0A%0A%0A%20%20%20%20%0A%20%20%20%20var%20tile_layer_1ef91896dc66474f83222ab4039acab5%20%3D%20L.tileLayer%28%0A%20%20%20%20%20%20%20%20%27https%3A//%7Bs%7D.tile.openstreetmap.org/%7Bz%7D/%7Bx%7D/%7By%7D.png%27%2C%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%22attribution%22%3A%20null%2C%0A%20%20%20%20%20%20%20%20%22detectRetina%22%3A%20false%2C%0A%20%20%20%20%20%20%20%20%22maxNativeZoom%22%3A%2018%2C%0A%20%20%20%20%20%20%20%20%22maxZoom%22%3A%2018%2C%0A%20%20%20%20%20%20%20%20%22minZoom%22%3A%200%2C%0A%20%20%20%20%20%20%20%20%22noWrap%22%3A%20false%2C%0A%20%20%20%20%20%20%20%20%22opacity%22%3A%201%2C%0A%20%20%20%20%20%20%20%20%22subdomains%22%3A%20%22abc%22%2C%0A%20%20%20%20%20%20%20%20%22tms%22%3A%20false%0A%7D%29.addTo%28map_e02ab327738e4179821f653b49a66421%29%3B%0A%20%20%20%20var%20tile_layer_4fe928f0e1c046c9a0ef46476273d68f%20%3D%20L.tileLayer%28%0A%20%20%20%20%20%20%20%20%27https%3A//earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/205e771992eeecb6e930a56a26fea09f-f10c5576ce622d955a400b285e49bc70/tiles/%7Bz%7D/%7Bx%7D/%7By%7D%27%2C%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%22attribution%22%3A%20%22Google%20Earth%20Engine%22%2C%0A%20%20%20%20%20%20%20%20%22detectRetina%22%3A%20false%2C%0A%20%20%20%20%20%20%20%20%22maxNativeZoom%22%3A%2018%2C%0A%20%20%20%20%20%20%20%20%22maxZoom%22%3A%2018%2C%0A%20%20%20%20%20%20%20%20%22minZoom%22%3A%200%2C%0A%20%20%20%20%20%20%20%20%22noWrap%22%3A%20false%2C%0A%20%20%20%20%20%20%20%20%22opacity%22%3A%201%2C%0A%20%20%20%20%20%20%20%20%22subdomains%22%3A%20%22abc%22%2C%0A%20%20%20%20%20%20%20%20%22tms%22%3A%20false%0A%7D%29.addTo%28map_e02ab327738e4179821f653b49a66421%29%3B%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20var%20geo_json_794c46da6c574076b9326d48633b62e4%20%3D%20L.geoJson%28%0A%20%20%20%20%20%20%20%20%20%20%20%20%7B%22features%22%3A%20%5B%7B%22geometry%22%3A%20%7B%22coordinates%22%3A%20%5B%5B%5B28.3159%2C%2037.0471%5D%2C%20%5B28.3566%2C%2037.0471%5D%2C%20%5B28.3566%2C%2037.0652%5D%2C%20%5B28.3159%2C%2037.0652%5D%2C%20%5B28.3159%2C%2037.0471%5D%5D%5D%2C%20%22type%22%3A%20%22Polygon%22%7D%2C%20%22properties%22%3A%20%7B%22highlight%22%3A%20%7B%7D%2C%20%22style%22%3A%20%7B%7D%7D%2C%20%22type%22%3A%20%22Feature%22%7D%5D%2C%20%22type%22%3A%20%22FeatureCollection%22%7D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%20%20%20%20%29.addTo%28map_e02ab327738e4179821f653b49a66421%20%29%3B%0A%20%20%20%20%20%20%20%20geo_json_794c46da6c574076b9326d48633b62e4.setStyle%28function%28feature%29%20%7Breturn%20feature.properties.style%3B%7D%29%3B%0A%20%20%20%20%20%20%20%20%0A%20%20%20%20var%20tile_layer_06dad931a7db4dc583973a50c3fc3a82%20%3D%20L.tileLayer%28%0A%20%20%20%20%20%20%20%20%27https%3A//earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/bdf575eff9be08718c6c87c7f5094188-bc2a514d95509f138fc4192348471647/tiles/%7Bz%7D/%7Bx%7D/%7By%7D%27%2C%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%22attribution%22%3A%20%22Google%20Earth%20Engine%22%2C%0A%20%20%20%20%20%20%20%20%22detectRetina%22%3A%20false%2C%0A%20%20%20%20%20%20%20%20%22maxNativeZoom%22%3A%2018%2C%0A%20%20%20%20%20%20%20%20%22maxZoom%22%3A%2018%2C%0A%20%20%20%20%20%20%20%20%22minZoom%22%3A%200%2C%0A%20%20%20%20%20%20%20%20%22noWrap%22%3A%20false%2C%0A%20%20%20%20%20%20%20%20%22opacity%22%3A%201%2C%0A%20%20%20%20%20%20%20%20%22subdomains%22%3A%20%22abc%22%2C%0A%20%20%20%20%20%20%20%20%22tms%22%3A%20false%0A%7D%29.addTo%28map_e02ab327738e4179821f653b49a66421%29%3B%0A%20%20%20%20var%20tile_layer_8d559aa733fc4644a256435103685b7d%20%3D%20L.tileLayer%28%0A%20%20%20%20%20%20%20%20%27https%3A//earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/72089158f7d9340f815eadf450ae5b22-83d545ff831de5de36ffe2a6f9e324b0/tiles/%7Bz%7D/%7Bx%7D/%7By%7D%27%2C%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%22attribution%22%3A%20%22Google%20Earth%20Engine%22%2C%0A%20%20%20%20%20%20%20%20%22detectRetina%22%3A%20false%2C%0A%20%20%20%20%20%20%20%20%22maxNativeZoom%22%3A%2018%2C%0A%20%20%20%20%20%20%20%20%22maxZoom%22%3A%2018%2C%0A%20%20%20%20%20%20%20%20%22minZoom%22%3A%200%2C%0A%20%20%20%20%20%20%20%20%22noWrap%22%3A%20false%2C%0A%20%20%20%20%20%20%20%20%22opacity%22%3A%201%2C%0A%20%20%20%20%20%20%20%20%22subdomains%22%3A%20%22abc%22%2C%0A%20%20%20%20%20%20%20%20%22tms%22%3A%20false%0A%7D%29.addTo%28map_e02ab327738e4179821f653b49a66421%29%3B%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20var%20layer_control_ae1fdf8e59a647bd9bbb965516b1ed79%20%3D%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20base_layers%20%3A%20%7B%20%22openstreetmap%22%20%3A%20tile_layer_1ef91896dc66474f83222ab4039acab5%2C%20%7D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20overlays%20%3A%20%7B%20%22Landsat8%22%20%3A%20tile_layer_4fe928f0e1c046c9a0ef46476273d68f%2C%22Marmaris%22%20%3A%20geo_json_794c46da6c574076b9326d48633b62e4%2C%22train%22%20%3A%20tile_layer_06dad931a7db4dc583973a50c3fc3a82%2C%22test%22%20%3A%20tile_layer_8d559aa733fc4644a256435103685b7d%2C%20%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20L.control.layers%28%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20layer_control_ae1fdf8e59a647bd9bbb965516b1ed79.base_layers%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20layer_control_ae1fdf8e59a647bd9bbb965516b1ed79.overlays%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7Bposition%3A%20%27topright%27%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20collapsed%3A%20true%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20autoZIndex%3A%20true%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%29.addTo%28map_e02ab327738e4179821f653b49a66421%29%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%0A%3C/script%3E onload=\"this.contentDocument.open();this.contentDocument.write(    decodeURIComponent(this.getAttribute('data-html')));this.contentDocument.close();\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ],
            "text/plain": [
              "<folium.folium.Map at 0x7f2a09500a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5gTZXnjiYtc"
      },
      "source": [
        "### **4. Preparing Train/Test Dataset**\n",
        "#### 4.1 Extract pixels values considering train/test dataset\n",
        "It will use the `ee.Image.sampleRegions` function to collocate of the train/test datasets for each L8 grid cell value. \n",
        "\n",
        "**sampleRegions** uses multiple regions (either points or polygons) and does exhaustive sampling in each region (all pixels). It converts each pixel of an image (at a given scale) that intersects one or more regions to a Feature, returning them as a FeatureCollection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSEpIt7jkCFk"
      },
      "source": [
        "# Extract pixels values considering train/test dataset\n",
        "train_db = l8.sampleRegions(collection=train_agriculture, properties=['landcover'], scale=30)\n",
        "test_db = l8.sampleRegions(collection=test_agriculture, properties=['landcover'], scale=30)\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "# Print the first couple points to verify.\n",
        "pprint({'training': train_db.first().getInfo()})\n",
        "pprint({'testing': test_db.first().getInfo()})\n",
        "pprint({'training size': train_db.size().getInfo()})\n",
        "pprint({'testing size': test_db.size().getInfo()})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfMmuelKkKPE"
      },
      "source": [
        "#### 4.2 Exporting train/test dataset to a storage bucket\n",
        "The train/test dataset will be stored into a Google **Cloud Storage Bucket (GCS)** to acces from both GEE and Tensorflow. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYqA9AOjlX6B",
        "outputId": "fede990e-00a6-4908-894a-f38f583da3e4"
      },
      "source": [
        "# Save dataset to Google Cloud Storage\n",
        "outputBucket = 'marmaris_agronomy' # replace with your cloud storage bucket \n",
        "\n",
        "# Before compiling, create a storage bucket in GCP\n",
        "# Make sure the bucket exists.\n",
        "print('Found cloud storage bucket.' if tf.io.gfile.exists('gs://' + outputBucket) \n",
        "    else 'Cloud storage bucket does not exist.')\n",
        "\n",
        "trainFilePrefix = 'TrainingAgriculture_'\n",
        "testFilePrefix = 'TestAgriculture_'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found cloud storage bucket.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXvKeKxtPyGn"
      },
      "source": [
        "#### **If there there is no train/test dataset storage bucket**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YXkCfnjlxWv"
      },
      "source": [
        "# Create tasks for exporting the dataset from GEE to Google storage\n",
        "trainingTask = ee.batch.Export.table.toCloudStorage(\n",
        "  collection=train_db,\n",
        "  description='Training Export',\n",
        "  fileNamePrefix=trainFilePrefix,\n",
        "  bucket=outputBucket,\n",
        "  fileFormat='TFRecord')\n",
        "\n",
        "testingTask = ee.batch.Export.table.toCloudStorage(\n",
        "  collection=test_db,\n",
        "  description='Testing Export',\n",
        "  fileNamePrefix=testFilePrefix,\n",
        "  bucket=outputBucket,\n",
        "  fileFormat='TFRecord')\n",
        "\n",
        "trainingTask.start()\n",
        "testingTask.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjepxQfsmDuO",
        "outputId": "b4a01682-9afe-478b-8751-844a98955f30"
      },
      "source": [
        "# Print all tasks.\n",
        "pprint(ee.batch.Task.list())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[<Task 6PPVRSPWIFOCHSFUMUKBSSQP EXPORT_FEATURES: Testing Export (READY)>,\n",
            " <Task N76HHBQEWPF6W3BP2YZDAC5A EXPORT_FEATURES: Training Export (READY)>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejSatCeMnHWi",
        "outputId": "1fa04019-a9dd-4644-b35e-526d06cd571d"
      },
      "source": [
        "file_extension = '.tfrecord.gz'\n",
        "trainFilePathc = 'gs://' + outputBucket + '/' + trainFilePrefix + file_extension\n",
        "testFilePathc = 'gs://' + outputBucket + '/' + testFilePrefix + file_extension\n",
        "\n",
        "\n",
        "print('Found training file.' if tf.io.gfile.exists(trainFilePathc) \n",
        "    else 'No training file found.')\n",
        "print('Found testing file.' if tf.io.gfile.exists(testFilePathc) \n",
        "    else 'No testing file found.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found training file.\n",
            "Found testing file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctiIQV5FnIZ3"
      },
      "source": [
        "# Monitor task progress\n",
        "import time \n",
        "while trainingTask.active():\n",
        "  print('Polling for task (id: {}).'.format(trainingTask.id))\n",
        "  time.sleep(5)\n",
        "while testingTask.active():\n",
        "  print('Polling for task (id: {}).'.format(testingTask.id))\n",
        "  time.sleep(5)\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70q3u-qznWWe"
      },
      "source": [
        "### **5. Creating TensorFlow Dataset**\n",
        "Read data from the storage bucket **TFRecord** file into a `tf.data.Dataset`. Pre-process the dataset to get it into a suitable format for input to the DNN model. \n",
        "For getting more details about  `tf.data.Dataset`see the [TFdoc](https://www.tensorflow.org/guide/premade_estimators#create_input_functions)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6DyAwk-ovnl"
      },
      "source": [
        "# Fullname train/test db\n",
        "#fileNameSuffix = 'ee_export.tfrecord.gz'\n",
        "fileNameSuffix = '.tfrecord.gz'\n",
        "trainFilePath = 'gs://' + outputBucket + '/' + trainFilePrefix + fileNameSuffix\n",
        "testFilePath = 'gs://' + outputBucket + '/' + testFilePrefix + fileNameSuffix\n",
        "\n",
        "def input_fn(fileNames, numEpochs=None, shuffle=True, batchSize=16):\n",
        "  # Read `TFRecordDatasets` \n",
        "  dataset = tf.data.TFRecordDataset(fileNames, compression_type='GZIP')\n",
        "\n",
        "  # Names of the features \n",
        "  feature_columns = {\n",
        "    'R': tf.io.FixedLenFeature([], dtype=tf.float32),  \n",
        "    'G': tf.io.FixedLenFeature([], dtype=tf.float32),  \n",
        "    'B': tf.io.FixedLenFeature([], dtype=tf.float32),    \n",
        "    'NDVI': tf.io.FixedLenFeature([], dtype=tf.float32),    \n",
        "    'landcover': tf.io.FixedLenFeature([], dtype=tf.float32)\n",
        "  }\n",
        "  \n",
        "  # Make a parsing function\n",
        "  def parse(example_proto):\n",
        "    parsed_features = tf.io.parse_single_example(example_proto, feature_columns)    \n",
        "    # Separate the class labels from the training features\n",
        "    labels = parsed_features.pop('landcover')\n",
        "    return parsed_features, tf.cast(labels, tf.int32)\n",
        "  \n",
        "  # Map the function over the dataset\n",
        "  dataset = dataset.map(parse, num_parallel_calls=5)\n",
        "  if shuffle:\n",
        "    dataset = dataset.shuffle(buffer_size = batchSize * 10)\n",
        "  dataset = dataset.batch(batchSize)\n",
        "  dataset = dataset.repeat(numEpochs)\n",
        "  \n",
        "  return dataset\n",
        "\n",
        "train_dba = input_fn(trainFilePath,100,True,32)\n",
        "test_dba = input_fn(testFilePath, numEpochs=1, batchSize=1, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AYSEdlxo919"
      },
      "source": [
        "### **6. Creating DNN Model with Keras**\n",
        "In this project, [TensorFlow Keras Sequential](https://www.tensorflow.org/guide/keras/sequential_model) is used as the DNN model.\n",
        "\n",
        "As explained in the definition of the problem, since the **binary classification** problem is defined in the given geographical area [1] whether it is vegetation or [2] a settlement area, in the model;\n",
        "- 2 (20x20 nodes) **Dense** layers,\n",
        "- 1 **Dropout** (regularization) layer set to 20% `weight_constraint` and\n",
        "- 1 **Output** layer is defined.\n",
        "\n",
        "Since the problem covered by the project covers non-linear classification, the nonlinear **Relu** (Rectified Linear Unit) activation function is applied, which assigns its own value to values below zero and values above zero for operations occurring in each node.\n",
        "\n",
        "With cross-entropy, *which allows the measurement of the distance from one probability distribution to another for classification,* we expect our network to estimate the correct class with a probability of 1.0.\n",
        "\n",
        "The **sigmoid** activation function is used to convert the actual valuable outputs generated by the output layer into probabilities.\n",
        "\n",
        "To obtain the final class estimate, Keras' default **accuracy** measure of 0.5 threshold probability (grade below 0.5, labeled 0 or above 1) is used.\n",
        "\n",
        "Additionally, **Early Stopping**, Tensorboard, and best model **callback** are added. A callback is a set of functions to be applied at given stages of the training procedure. You can found more details [here](https://keras.io/callbacks/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVHT_UjRtA6Q"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ttz46U5MsPdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecd0e7b5-ec9d-4db3-ac6f-24dd6cf7900a"
      },
      "source": [
        "# TensorFlow Keras Sequential Model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow import feature_column\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "bands = ['R','G','B','NDVI']\n",
        "\n",
        "# Create a dense `Tensor` based on given `feature_columns`.\n",
        "feature_columns = [feature_column.numeric_column(x) for x in bands]\n",
        "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
        "\n",
        "# Initialize the DNN model\n",
        "he_init = tf.keras.initializers.he_uniform(seed=None)\n",
        "\n",
        "# Define the layers in the model.\n",
        "model = tf.keras.Sequential([\n",
        "  feature_layer,  \n",
        "  layers.Dense(20, activation='relu',kernel_initializer=he_init),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  layers.Dense(20, activation='relu',kernel_initializer=he_init),\n",
        "  layers.Dense(1, activation='sigmoid',kernel_initializer=he_init)\n",
        "])\n",
        "\n",
        "# Callbacks time\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "es = EarlyStopping(monitor='val_loss', patience=10)\n",
        "mcp = ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "\n",
        "# Compile the model with the specified loss function.\n",
        "model.compile(optimizer=keras.optimizers.SGD(momentum=0.01, nesterov=True),\n",
        "              loss='binary_crossentropy',              \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fit the model to the training data.\n",
        "history = model.fit(x=train_dba,\n",
        "          epochs=50,\n",
        "          steps_per_epoch=100,\n",
        "          callbacks=[tensorboard_callback,es,mcp],          \n",
        "          validation_data=test_dba)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'B': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'G': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'NDVI': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'R': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'B': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'G': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'NDVI': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'R': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 0.7028 - accuracy: 0.5138WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'B': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float32>, 'G': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=float32>, 'NDVI': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float32>, 'R': <tf.Tensor 'ExpandDims_3:0' shape=(None, 1) dtype=float32>}\n",
            "Consider rewriting this model with the Functional API.\n",
            "100/100 [==============================] - 2s 12ms/step - loss: 0.7038 - accuracy: 0.5028 - val_loss: 0.6864 - val_accuracy: 0.5100\n",
            "Epoch 2/50\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.6799 - accuracy: 0.5566 - val_loss: 0.6567 - val_accuracy: 0.7800\n",
            "Epoch 3/50\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.6629 - accuracy: 0.6578 - val_loss: 0.6348 - val_accuracy: 0.7850\n",
            "Epoch 4/50\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.6508 - accuracy: 0.6916 - val_loss: 0.6201 - val_accuracy: 0.7850\n",
            "Epoch 5/50\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.6397 - accuracy: 0.7056 - val_loss: 0.6086 - val_accuracy: 0.7900\n",
            "Epoch 6/50\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.6290 - accuracy: 0.7216 - val_loss: 0.5981 - val_accuracy: 0.7900\n",
            "Epoch 7/50\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.6229 - accuracy: 0.7191 - val_loss: 0.5881 - val_accuracy: 0.7800\n",
            "Epoch 8/50\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.6166 - accuracy: 0.7175 - val_loss: 0.5779 - val_accuracy: 0.7850\n",
            "Epoch 9/50\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.6087 - accuracy: 0.7212 - val_loss: 0.5681 - val_accuracy: 0.7750\n",
            "Epoch 10/50\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.6020 - accuracy: 0.7150 - val_loss: 0.5577 - val_accuracy: 0.7900\n",
            "Epoch 11/50\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.5917 - accuracy: 0.7312 - val_loss: 0.5480 - val_accuracy: 0.7800\n",
            "Epoch 12/50\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.5891 - accuracy: 0.7191 - val_loss: 0.5382 - val_accuracy: 0.7800\n",
            "Epoch 13/50\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.5773 - accuracy: 0.7281 - val_loss: 0.5293 - val_accuracy: 0.7800\n",
            "Epoch 14/50\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.5704 - accuracy: 0.7294 - val_loss: 0.5203 - val_accuracy: 0.7750\n",
            "Epoch 15/50\n",
            "100/100 [==============================] - 1s 7ms/step - loss: 0.5668 - accuracy: 0.7259 - val_loss: 0.5116 - val_accuracy: 0.7750\n",
            "Epoch 16/50\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.5553 - accuracy: 0.7366 - val_loss: 0.5023 - val_accuracy: 0.7850\n",
            "Epoch 17/50\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.5497 - accuracy: 0.7391 - val_loss: 0.4965 - val_accuracy: 0.7800\n",
            "Epoch 18/50\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.5497 - accuracy: 0.7322 - val_loss: 0.4886 - val_accuracy: 0.7750\n",
            "Epoch 19/50\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.5401 - accuracy: 0.7447 - val_loss: 0.4842 - val_accuracy: 0.7800\n",
            "Epoch 20/50\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.5305 - accuracy: 0.7400 - val_loss: 0.4753 - val_accuracy: 0.7850\n",
            "Epoch 21/50\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.5332 - accuracy: 0.7366 - val_loss: 0.4731 - val_accuracy: 0.7800\n",
            "Epoch 22/50\n",
            "100/100 [==============================] - 1s 9ms/step - loss: 0.5280 - accuracy: 0.7462 - val_loss: 0.4680 - val_accuracy: 0.7800\n",
            "Epoch 23/50\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.5178 - accuracy: 0.7556 - val_loss: 0.4634 - val_accuracy: 0.7800\n",
            "Epoch 24/50\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.5238 - accuracy: 0.7444 - val_loss: 0.4608 - val_accuracy: 0.7800\n",
            "Epoch 25/50\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.5185 - accuracy: 0.7469 - val_loss: 0.4581 - val_accuracy: 0.7800\n",
            "Epoch 26/50\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 5000 batches). You may need to use the repeat() function when building your dataset.\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7469 - val_loss: 0.4581 - val_accuracy: 0.7800\n",
            "Model: \"sequential_80\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_features_20 (DenseFeat multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_240 (Dense)            multiple                  100       \n",
            "_________________________________________________________________\n",
            "dropout_80 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense_241 (Dense)            multiple                  420       \n",
            "_________________________________________________________________\n",
            "dense_242 (Dense)            multiple                  21        \n",
            "=================================================================\n",
            "Total params: 541\n",
            "Trainable params: 541\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "cgNX_Ymts3oL",
        "outputId": "694f86b4-1c37-47df-db34-b3374cdbe5f3"
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(14,3))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x216 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRU1ECJ3tQ15",
        "outputId": "872cd78c-ca37-484a-b370-0be51eef7d11"
      },
      "source": [
        "model.load_weights(\"best_model.h5\")\n",
        "model.evaluate(x = test_dba)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200/200 [==============================] - 0s 1ms/step - loss: 0.4581 - accuracy: 0.7800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4581398069858551, 0.7799999713897705]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sTzt7JTtULE"
      },
      "source": [
        "%tensorboard --logdir logs\n",
        "#Use '!kill (pid)' to kill it"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhP6CLfPJXmh"
      },
      "source": [
        "### **7. Collective Learning** - from Fetch.AI\n",
        "<center>\n",
        "<img src=\"https://miro.medium.com/max/3840/1*5rbqEVTmPsfjKPf09a5hrQ.jpeg\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOrBu4yBBuLG"
      },
      "source": [
        "<h2>What is Collective Learning</h2>\n",
        "\n",
        "Collective Learning or colearn is a library that enables privacy-preserving decentralized machine learning tasks on the [FET network](https://fetch.ai/).\n",
        "\n",
        "**Blockchain**-mediated collective learning system enables multiple stakeholders to build a shared machine learning model without needing to rely on a central authority, and without revealing sensitive information about their dataset to the other stakeholders.\n",
        "\n",
        "The collective learning protocol allows learners to collaborate on training a model without requiring trust between the participants. Learners vote on updates to the model, and only updates which pass the quality threshold are accepted. This makes the system robust to attempts to interfere with the model by providing bad updates.\n",
        "\n",
        "For more information [Fetch.ai Colearn Web Site](https://docs.fetch.ai/colearn/)\n",
        "\n",
        "<h2>How Training Works</h2>\n",
        "<p>Training occurs in rounds; during each round the learners attempt to improve the performance of the global shared model. To do so each round an update of the global model (for example a new set of weights in a neural network) is proposed. The learners then evaluate the update and decide if the new model is better than the current global model.\n",
        "\n",
        "The detailed steps of a round updating a global model M are as follows:\n",
        "</p>\n",
        "\n",
        "*   One of the learners is selected and proposes a new updated model M’\n",
        "*   The rest of the learners validate M’\n",
        "*   If M’ has better performance than M against their private data set then the learner votes to approve\n",
        "*   If not the learner votes to reject\n",
        "*   The total votes are tallied\n",
        "*   If more than some threshold (typically 50%) of learners approve then M’ becomes the new global model. If not, M continues to be the global model\n",
        "*   A new round begins.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://fetch.ai/wp-content/uploads/2020/06/Collective-Learning-Graphic-New.png\" with=\"400\" height=\"400\">\n",
        "</center> \n",
        "\n",
        "You can review the open source code on Collective Learning [Github repository](https://github.com/fetchai/colearn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LSmfyvIAk9O"
      },
      "source": [
        "#### 7.1 Initialize Colearn\n",
        "I deployed related modules to my Google Drive repository.\n",
        "You can initialize colearn classes and functions by using the -m options stops the interactive mode, and loads the module following the -m - in this case it loads the pip module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vOpOMLoDVqm"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW1JWjz3Bhny"
      },
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/colearn\n",
        "!pip install pydantic\n",
        "!python -m colearn.training\n",
        "!python -m colearn.utils.plot\n",
        "!python -m colearn.utils.results\n",
        "!python -m colearn_keras.keras_learner "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jbf96c5qKj8o"
      },
      "source": [
        "#### 7.2 Load dat, Define the model, Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QK5n-jCJXPc"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "from colearn.training import set_equal_weights, initial_result, collective_learning_round\n",
        "from colearn.utils.plot import ColearnPlot\n",
        "from colearn.utils.results import Results, print_results\n",
        "from colearn_keras.keras_learner import KerasLearner\n",
        "\n",
        "\n",
        "steps_per_epoch = 100\n",
        "vote_batches = 15  \n",
        "n_learners = 5\n",
        "n_rounds = 20 \n",
        "vote_threshold = 0.5\n",
        "\n",
        "bands = ['R','G','B','NDVI']\n",
        "# Create a dense `Tensor` based on given `feature_columns`.\n",
        "feature_columns = [feature_column.numeric_column(x) for x in bands]\n",
        "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
        "\n",
        "# Initialize the DNN model\n",
        "he_init = tf.keras.initializers.he_uniform(seed=None)\n",
        "\n",
        "def get_model(): \n",
        "    # Define the layers in the model.\n",
        "    model = tf.keras.Sequential([\n",
        "      feature_layer,  \n",
        "      layers.Dense(10, activation='relu',kernel_initializer=he_init),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      layers.Dense(10, activation='relu',kernel_initializer=he_init),\n",
        "      layers.Dense(1, activation='sigmoid',kernel_initializer=he_init)\n",
        "    ])\n",
        "\n",
        "    # Callbacks \n",
        "    logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "    es = EarlyStopping(monitor='val_loss', patience=10)\n",
        "    mcp = ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "    # Compile the model with the specified loss function.\n",
        "    model.compile(optimizer=keras.optimizers.SGD(momentum=0.01, nesterov=True),\n",
        "                  loss='binary_crossentropy',              \n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "train_dba = input_fn(trainFilePath,100,True,32)\n",
        "test_dba = input_fn(testFilePath,100,True,32)\n",
        "train_datasets = [train_dba.shard(n_learners, i) for i in range(n_learners)]\n",
        "test_datasets = [test_dba.shard(n_learners, i) for i in range(n_learners)]\n",
        "\n",
        "all_learner_models = []\n",
        "for i in range(n_learners):\n",
        "    model = get_model()\n",
        "    all_learner_models.append(\n",
        "        KerasLearner(\n",
        "            model=model,\n",
        "            train_loader=train_datasets[i],\n",
        "            test_loader=test_datasets[i],\n",
        "            minimise_criterion=False,\n",
        "            criterion=\"accuracy\",\n",
        "            model_fit_kwargs={\"steps_per_epoch\": steps_per_epoch, \"callbacks\": [tensorboard_callback,es,mcp], \"validation_data\": test_datasets[i]},\n",
        "            model_evaluate_kwargs={\"steps\": vote_batches}            \n",
        "        ))\n",
        "\n",
        "set_equal_weights(all_learner_models)\n",
        "\n",
        "results = Results()\n",
        "# Get initial score\n",
        "results.data.append(initial_result(all_learner_models))\n",
        "\n",
        "plot = ColearnPlot(score_name=all_learner_models[0].criterion)\n",
        "\n",
        "for round_index in range(n_rounds):\n",
        "    results.data.append(\n",
        "        collective_learning_round(all_learner_models,\n",
        "                                  vote_threshold, round_index)\n",
        "    )\n",
        "\n",
        "    print_results(results)\n",
        "    plot.plot_results_and_votes(results)\n",
        "\n",
        "plot.block()\n",
        "\n",
        "print(\"Colearn Example Finished!\")    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLhas1BBtwjc"
      },
      "source": [
        "### **8. Prediction**\n",
        "#### 8.1 Preparing Lansat 8 imagery"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0neqVuC0tsvd"
      },
      "source": [
        "l8 = ee.ImageCollection(\"LANDSAT/LC08/C01/T1_SR\")\\\n",
        "               .filterBounds(Marmaris)\\\n",
        "               .filterDate('2019-01-01', '2019-12-31')\\\n",
        "               .filter(ee.Filter.lt('CLOUD_COVER', 20))\\\n",
        "               .map(maskS2clouds)\\\n",
        "               .median()\\\n",
        "               .multiply(0.0001)\\\n",
        "               .clip(Marmaris)\n",
        "\n",
        "l8_ndvi = l8.normalizedDifference(NDVI_bands).rename(['NDVI'])\n",
        "l8_rgb = l8.select(RGB_bands).rename(['R','G','B']) \n",
        "l8 = l8_rgb.addBands(l8_ndvi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUFjaxiOuCJX"
      },
      "source": [
        "#### 8.2 Exporting the result to Storage Bucket\n",
        "For export the results to the Google Cloud Storage, it's preferred defines the following `formatOptions` parameters to save memory:\n",
        "\n",
        "- **patchDimensions**:\tPatch dimensions tiled over the export area, covering every pixel in the bounding box exactly once (except when the patch dimensions do not evenly divide the bounding box in which case the lower and right sides are trimmed).\n",
        "\n",
        "- **compressed**: If true, compresses the .tfrecord files with gzip and appends the \".gz\" suffix\t\n",
        "\n",
        "See all the paramerters [here](https://developers.google.com/earth-engine/exporting#configuration-parameters)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kco8PL4VtvqQ"
      },
      "source": [
        "imageFilePrefix = 'MarmarisAgronomi'\n",
        "\n",
        "# Specify patch and file dimensions.\n",
        "imageExportFormatOptions = {\n",
        "  'patchDimensions': [64, 64],  \n",
        "  'maxFileSize': 100000000,    \n",
        "  'compressed': True\n",
        "}\n",
        "\n",
        "# Setup the task.\n",
        "imageTask = ee.batch.Export.image.toCloudStorage(\n",
        "  image=l8,\n",
        "  description='Image Export',\n",
        "  fileNamePrefix=imageFilePrefix,\n",
        "  bucket=outputBucket,\n",
        "  scale=30,\n",
        "  fileFormat='TFRecord',\n",
        "  region=Marmaris.getInfo()['coordinates'],\n",
        "  formatOptions=imageExportFormatOptions,\n",
        ")\n",
        "\n",
        "imageTask.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmTQGqPhuziB"
      },
      "source": [
        "import time \n",
        "while imageTask.active():\n",
        "  print('Polling for task (id: {}).'.format(imageTask.id))\n",
        "  time.sleep(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVJOR_mKu0uJ"
      },
      "source": [
        "#### 8.3 Classifying the image\n",
        "To classify the image that is exported from GEE to Storage Bucket using Tensorflow,  a JSON sidecar file called \"the mixer\" describes the format and geo-referencing of the image.\n",
        "\n",
        "There will be the image files and the mixer file, getting some info out of the mixer that will be useful during model inference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvTTpR46wPou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bec1aebd-3da1-4161-ce04-dd8de9f8ecc7"
      },
      "source": [
        "filesList = !gsutil ls 'gs://'{outputBucket}\n",
        "exportFilesList = [s for s in filesList if imageFilePrefix in s]\n",
        "\n",
        "# Get the list of image files and the JSON mixer file.\n",
        "imageFilesList = []\n",
        "jsonFile = None\n",
        "for f in exportFilesList:\n",
        "  if f.endswith('.tfrecord.gz'):\n",
        "    imageFilesList.append(f)\n",
        "  elif f.endswith('.json'):\n",
        "    jsonFile = f\n",
        "\n",
        "# Make sure the files are in the right order.\n",
        "print(jsonFile)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gs://marmaris_agronomy/MarmarisAgronomi.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bfu_qPpTwVlL"
      },
      "source": [
        "#### 8.4 Load the contents of the mixer file to a JSON object\n",
        "The mixer contains metadata and geo-referencing information for the exported patches, each of which is in a different file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWtxn4HFwuuB"
      },
      "source": [
        "import json\n",
        "from pprint import pprint \n",
        "\n",
        "jsonText = !gsutil cat {jsonFile}\n",
        "# Get a single string w/ newlines from the IPython.utils.text.SList\n",
        "mixer = json.loads(jsonText.nlstr)\n",
        "pprint(mixer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csKTtPUvw3OA"
      },
      "source": [
        "#### 8.5 Feeding trained model to make predictions\n",
        "The next function, mainly, is about the pixels are written into records as patches, we need to read the patches in as one big tensor (one patch for each band), then flatten them into lots of little tensors. \n",
        "\n",
        "Once the predict_input_fn is defined, that can handle the shape of the image data, all you need to do is feed it directly to the trained model to make predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nauiIK9wyBAp"
      },
      "source": [
        "def predict_input_fn(fileNames,patch,bands):\n",
        "\n",
        "  # You have to know the following from your export.\n",
        "  PATCH_WIDTH, PATCH_HEIGHT = patch\n",
        "  PATCH_DIMENSIONS_FLAT = [PATCH_WIDTH * PATCH_HEIGHT, 1]\n",
        "\n",
        "  # Note that the tensors are in the shape of a patch, one patch for each band.\n",
        "  imageColumns = [\n",
        "    tf.io.FixedLenFeature(shape=PATCH_DIMENSIONS_FLAT, dtype=tf.float32) \n",
        "      for k in bands\n",
        "  ]\n",
        "\n",
        "  featuresDict = dict(zip(bands, imageColumns))\n",
        "  dataset = tf.data.TFRecordDataset(fileNames, compression_type='GZIP')\n",
        "  \n",
        "  # Make a parsing function\n",
        "  def parse_image(example_proto):\n",
        "    parsed_features = tf.io.parse_single_example(example_proto, featuresDict)\n",
        "    return parsed_features\n",
        "\n",
        "  dataset = dataset.map(parse_image, num_parallel_calls=4)\n",
        "  \n",
        "  # Break our long tensors into many littler ones\n",
        "  #https://stackoverflow.com/questions/50530806/using-flat-map-in-tensorflows-dataset-api\n",
        "  dataset = dataset.flat_map(lambda features: tf.data.Dataset.from_tensor_slices(features))\n",
        "\n",
        "  # Read in batches corresponding to patch size.\n",
        "  dataset = dataset.batch(PATCH_WIDTH * PATCH_HEIGHT)\n",
        "\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFVnrtFZyE6k"
      },
      "source": [
        "predict_db = predict_input_fn(fileNames=imageFilesList,patch=[64,64],bands=['R', 'G', 'B', 'NDVI'])\n",
        "predictions = model.predict(predict_db)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enFdKCnuyIHD"
      },
      "source": [
        "#### 8.6 Dumping every patch-worth of predictions\n",
        "Every patch-worth of predictions, it'll be dumped an example into the output file with a single feature that holds our predictions. Since our predictions are already in the order of the exported data, the patches we create here will also be in the right order.\n",
        "\n",
        "There is a `np.array` of probabilities in \"predictions\" to write them back into a file. It will write directly from TensorFlow to a file in the output Cloud Storage bucket.\n",
        "\n",
        "Iterate over the list and write the probabilities in patches. Specifically, we need to write the pixels into the file as patches in the same order they came out. The records are written as serialized tf.train.Example protos. This might take a while."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2enKgT_ydtO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f60104d-6cd5-4195-d139-8369239b4baa"
      },
      "source": [
        "PATCH_WIDTH , PATCH_HEIGHT = [64,64]\n",
        "outputImageFile = 'gs://' + outputBucket + '/MarmarisAgronomi.TFRecord'\n",
        "writer = tf.io.TFRecordWriter(outputImageFile)\n",
        "\n",
        "patch = []\n",
        "curPatch = 1\n",
        "for  prediction in predictions:\n",
        "  patch.append(prediction)\n",
        "  \n",
        "  if (len(patch) == PATCH_WIDTH * PATCH_HEIGHT):\n",
        "    print('Done with patch ' + str(curPatch) + '...')    \n",
        "    # Create an example\n",
        "    example = tf.train.Example(\n",
        "      features=tf.train.Features(\n",
        "        feature={\n",
        "          'crop_prob': tf.train.Feature(\n",
        "              float_list=tf.train.FloatList(\n",
        "                  value=patch))\n",
        "        }\n",
        "      )\n",
        "    )\n",
        "    \n",
        "    writer.write(example.SerializeToString())\n",
        "    patch = []\n",
        "    curPatch += 1 \n",
        "\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done with patch 1...\n",
            "Done with patch 2...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AsqSpk_z1k7"
      },
      "source": [
        "#### 8.7 Uploading the classifications to an Earth Engine asset\n",
        "\n",
        "At this stage, there should be a predictions TFRecord file sitting in the output Cloud Storage bucket. Use the gsutil command to verify that the predictions image (and associated mixer JSON) exist and have non-zero size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyziCe5m0OmF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d433bc18-2ce1-4383-d1b7-e13749f96b6c"
      },
      "source": [
        "!gsutil ls -l {outputImageFile}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     32862  2021-05-31T19:16:05Z  gs://marmaris_agronomy/MarmarisAgronomi.TFRecord\n",
            "TOTAL: 1 objects, 32862 bytes (32.09 KiB)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BbEfare0SQn"
      },
      "source": [
        "Upload the image to Earth Engine directly from the Cloud Storage bucket with the [earthengine command](https://developers.google.com/earth-engine/command_line#upload). Provide both the image TFRecord file and the JSON file as arguments to earthengine upload."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_WATfLb0tBZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d215631-9739-4ad5-b334-bae232d74060"
      },
      "source": [
        "USER_NAME = 'patikan' # replace with your GEE username\n",
        "outputAssetID = 'users/' + USER_NAME + '/MarmarisAgronomi'\n",
        "print('Writing to ' + outputAssetID)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing to users/patikan/MarmarisAgronomi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fjsgfse05bC"
      },
      "source": [
        "Starting the upload - this step might take a while."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhRZBGM01AJS"
      },
      "source": [
        "print('outputAssetID: ' + outputAssetID + 'outputImageFile: ' +  outputImageFile + 'jsonFile: ' + jsonFile)\n",
        "!earthengine upload image --asset_id={outputAssetID} {outputImageFile} {jsonFile}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL2VYypQ1NpS"
      },
      "source": [
        "#### 8.8 Displaying Prediction\n",
        "Display the results for the selected area by using Folium!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7VA_1Wp1gVg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 968
        },
        "outputId": "7e51bf6a-9568-410e-d0d7-f57cac30d726"
      },
      "source": [
        "ProbsImage = ee.Image(outputAssetID)\n",
        "predictionsImage = ee.Image(outputAssetID).gte(0.500)\n",
        "dicc = {'Marmaris':l8Mapid,'CropProbability':ProbsImage.getMapId(),\n",
        "        'Crop':predictionsImage.getMapId()}\n",
        "\n",
        "center = Marmaris.centroid().getInfo()['coordinates']\n",
        "center.reverse()\n",
        "\n",
        "Mapdisplay(center=center,dicc=dicc,zoom_start=12)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe src=\"about:blank\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" data-html=%3C%21DOCTYPE%20html%3E%0A%3Chead%3E%20%20%20%20%0A%20%20%20%20%3Cmeta%20http-equiv%3D%22content-type%22%20content%3D%22text/html%3B%20charset%3DUTF-8%22%20/%3E%0A%20%20%20%20%3Cscript%3EL_PREFER_CANVAS%3Dfalse%3B%20L_NO_TOUCH%3Dfalse%3B%20L_DISABLE_3D%3Dfalse%3B%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//cdn.jsdelivr.net/npm/leaflet%401.4.0/dist/leaflet.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//code.jquery.com/jquery-1.12.4.min.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js%22%3E%3C/script%3E%0A%20%20%20%20%3Cscript%20src%3D%22https%3A//cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js%22%3E%3C/script%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//cdn.jsdelivr.net/npm/leaflet%401.4.0/dist/leaflet.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap-theme.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css%22/%3E%0A%20%20%20%20%3Clink%20rel%3D%22stylesheet%22%20href%3D%22https%3A//rawcdn.githack.com/python-visualization/folium/master/folium/templates/leaflet.awesome.rotate.css%22/%3E%0A%20%20%20%20%3Cstyle%3Ehtml%2C%20body%20%7Bwidth%3A%20100%25%3Bheight%3A%20100%25%3Bmargin%3A%200%3Bpadding%3A%200%3B%7D%3C/style%3E%0A%20%20%20%20%3Cstyle%3E%23map%20%7Bposition%3Aabsolute%3Btop%3A0%3Bbottom%3A0%3Bright%3A0%3Bleft%3A0%3B%7D%3C/style%3E%0A%20%20%20%20%0A%20%20%20%20%3Cmeta%20name%3D%22viewport%22%20content%3D%22width%3Ddevice-width%2C%0A%20%20%20%20%20%20%20%20initial-scale%3D1.0%2C%20maximum-scale%3D1.0%2C%20user-scalable%3Dno%22%20/%3E%0A%20%20%20%20%3Cstyle%3E%23map_90cb4c5b630841f6998a222c4d37042e%20%7B%0A%20%20%20%20%20%20%20%20position%3A%20relative%3B%0A%20%20%20%20%20%20%20%20width%3A%20100.0%25%3B%0A%20%20%20%20%20%20%20%20height%3A%20100.0%25%3B%0A%20%20%20%20%20%20%20%20left%3A%200.0%25%3B%0A%20%20%20%20%20%20%20%20top%3A%200.0%25%3B%0A%20%20%20%20%20%20%20%20%7D%0A%20%20%20%20%3C/style%3E%0A%3C/head%3E%0A%3Cbody%3E%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%3Cdiv%20class%3D%22folium-map%22%20id%3D%22map_90cb4c5b630841f6998a222c4d37042e%22%20%3E%3C/div%3E%0A%3C/body%3E%0A%3Cscript%3E%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20var%20bounds%20%3D%20null%3B%0A%20%20%20%20%0A%0A%20%20%20%20var%20map_90cb4c5b630841f6998a222c4d37042e%20%3D%20L.map%28%0A%20%20%20%20%20%20%20%20%27map_90cb4c5b630841f6998a222c4d37042e%27%2C%20%7B%0A%20%20%20%20%20%20%20%20center%3A%20%5B37.05615137814542%2C%2028.33624999999642%5D%2C%0A%20%20%20%20%20%20%20%20zoom%3A%2012%2C%0A%20%20%20%20%20%20%20%20maxBounds%3A%20bounds%2C%0A%20%20%20%20%20%20%20%20layers%3A%20%5B%5D%2C%0A%20%20%20%20%20%20%20%20worldCopyJump%3A%20false%2C%0A%20%20%20%20%20%20%20%20crs%3A%20L.CRS.EPSG3857%2C%0A%20%20%20%20%20%20%20%20zoomControl%3A%20true%2C%0A%20%20%20%20%20%20%20%20%7D%29%3B%0A%0A%0A%20%20%20%20%0A%20%20%20%20var%20tile_layer_bb65420016674e718f3c4a3c0aae8234%20%3D%20L.tileLayer%28%0A%20%20%20%20%20%20%20%20%27https%3A//%7Bs%7D.tile.openstreetmap.org/%7Bz%7D/%7Bx%7D/%7By%7D.png%27%2C%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%22attribution%22%3A%20null%2C%0A%20%20%20%20%20%20%20%20%22detectRetina%22%3A%20false%2C%0A%20%20%20%20%20%20%20%20%22maxNativeZoom%22%3A%2018%2C%0A%20%20%20%20%20%20%20%20%22maxZoom%22%3A%2018%2C%0A%20%20%20%20%20%20%20%20%22minZoom%22%3A%200%2C%0A%20%20%20%20%20%20%20%20%22noWrap%22%3A%20false%2C%0A%20%20%20%20%20%20%20%20%22opacity%22%3A%201%2C%0A%20%20%20%20%20%20%20%20%22subdomains%22%3A%20%22abc%22%2C%0A%20%20%20%20%20%20%20%20%22tms%22%3A%20false%0A%7D%29.addTo%28map_90cb4c5b630841f6998a222c4d37042e%29%3B%0A%20%20%20%20var%20tile_layer_101d1ad35df44450821a5eadc9b395c6%20%3D%20L.tileLayer%28%0A%20%20%20%20%20%20%20%20%27https%3A//earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/205e771992eeecb6e930a56a26fea09f-f10c5576ce622d955a400b285e49bc70/tiles/%7Bz%7D/%7Bx%7D/%7By%7D%27%2C%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%22attribution%22%3A%20%22Google%20Earth%20Engine%22%2C%0A%20%20%20%20%20%20%20%20%22detectRetina%22%3A%20false%2C%0A%20%20%20%20%20%20%20%20%22maxNativeZoom%22%3A%2018%2C%0A%20%20%20%20%20%20%20%20%22maxZoom%22%3A%2018%2C%0A%20%20%20%20%20%20%20%20%22minZoom%22%3A%200%2C%0A%20%20%20%20%20%20%20%20%22noWrap%22%3A%20false%2C%0A%20%20%20%20%20%20%20%20%22opacity%22%3A%201%2C%0A%20%20%20%20%20%20%20%20%22subdomains%22%3A%20%22abc%22%2C%0A%20%20%20%20%20%20%20%20%22tms%22%3A%20false%0A%7D%29.addTo%28map_90cb4c5b630841f6998a222c4d37042e%29%3B%0A%20%20%20%20var%20tile_layer_7c79fdbaab24437db135c07d84b50933%20%3D%20L.tileLayer%28%0A%20%20%20%20%20%20%20%20%27https%3A//earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/f305b907ccadd7bb0e72d6376ac8d111-1cc629211424f8e679c1ce08985ef520/tiles/%7Bz%7D/%7Bx%7D/%7By%7D%27%2C%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%22attribution%22%3A%20%22Google%20Earth%20Engine%22%2C%0A%20%20%20%20%20%20%20%20%22detectRetina%22%3A%20false%2C%0A%20%20%20%20%20%20%20%20%22maxNativeZoom%22%3A%2018%2C%0A%20%20%20%20%20%20%20%20%22maxZoom%22%3A%2018%2C%0A%20%20%20%20%20%20%20%20%22minZoom%22%3A%200%2C%0A%20%20%20%20%20%20%20%20%22noWrap%22%3A%20false%2C%0A%20%20%20%20%20%20%20%20%22opacity%22%3A%201%2C%0A%20%20%20%20%20%20%20%20%22subdomains%22%3A%20%22abc%22%2C%0A%20%20%20%20%20%20%20%20%22tms%22%3A%20false%0A%7D%29.addTo%28map_90cb4c5b630841f6998a222c4d37042e%29%3B%0A%20%20%20%20var%20tile_layer_674ce7fb20944210987b0afec9137aa5%20%3D%20L.tileLayer%28%0A%20%20%20%20%20%20%20%20%27https%3A//earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/maps/dba656e455694f072fc150b830da6eb9-70c7697c49ccf0e781c4102635327e5a/tiles/%7Bz%7D/%7Bx%7D/%7By%7D%27%2C%0A%20%20%20%20%20%20%20%20%7B%0A%20%20%20%20%20%20%20%20%22attribution%22%3A%20%22Google%20Earth%20Engine%22%2C%0A%20%20%20%20%20%20%20%20%22detectRetina%22%3A%20false%2C%0A%20%20%20%20%20%20%20%20%22maxNativeZoom%22%3A%2018%2C%0A%20%20%20%20%20%20%20%20%22maxZoom%22%3A%2018%2C%0A%20%20%20%20%20%20%20%20%22minZoom%22%3A%200%2C%0A%20%20%20%20%20%20%20%20%22noWrap%22%3A%20false%2C%0A%20%20%20%20%20%20%20%20%22opacity%22%3A%201%2C%0A%20%20%20%20%20%20%20%20%22subdomains%22%3A%20%22abc%22%2C%0A%20%20%20%20%20%20%20%20%22tms%22%3A%20false%0A%7D%29.addTo%28map_90cb4c5b630841f6998a222c4d37042e%29%3B%0A%20%20%20%20%0A%20%20%20%20%20%20%20%20%20%20%20%20var%20layer_control_092d3fe0d4d24cc098cba4c4dbb0af4a%20%3D%20%7B%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20base_layers%20%3A%20%7B%20%22openstreetmap%22%20%3A%20tile_layer_bb65420016674e718f3c4a3c0aae8234%2C%20%7D%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20overlays%20%3A%20%7B%20%22Marmaris%22%20%3A%20tile_layer_101d1ad35df44450821a5eadc9b395c6%2C%22CropProbability%22%20%3A%20tile_layer_7c79fdbaab24437db135c07d84b50933%2C%22Crop%22%20%3A%20tile_layer_674ce7fb20944210987b0afec9137aa5%2C%20%7D%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20L.control.layers%28%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20layer_control_092d3fe0d4d24cc098cba4c4dbb0af4a.base_layers%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20layer_control_092d3fe0d4d24cc098cba4c4dbb0af4a.overlays%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7Bposition%3A%20%27topright%27%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20collapsed%3A%20true%2C%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20autoZIndex%3A%20true%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%7D%29.addTo%28map_90cb4c5b630841f6998a222c4d37042e%29%3B%0A%20%20%20%20%20%20%20%20%20%20%20%20%0A%20%20%20%20%20%20%20%20%0A%3C/script%3E onload=\"this.contentDocument.open();this.contentDocument.write(    decodeURIComponent(this.getAttribute('data-html')));this.contentDocument.close();\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
            ],
            "text/plain": [
              "<folium.folium.Map at 0x7f29fb6e5590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    }
  ]
} 
